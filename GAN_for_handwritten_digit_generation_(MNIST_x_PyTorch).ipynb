{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHj6E1sNp2uVcE84pjs5p3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanayPhatak/Google_Colab_Projects/blob/main/GAN_for_handwritten_digit_generation_(MNIST_x_PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Network\n",
        "## Generate handwritten digits - similar to MNIST dataset."
      ],
      "metadata": {
        "id": "KByfg90usT5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "iXMnbW3ito5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision import datasets, transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "mXoBy_E2tG6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurations"
      ],
      "metadata": {
        "id": "WNnUlEXetKE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "batch_size = 128\n",
        "noise_dim = 64\n",
        "\n",
        "# Optimizer Parameters\n",
        "lr = 0.0002\n",
        "beta_1 = 0.5\n",
        "beta_2 = 0.99\n",
        "\n",
        "# Training variables\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "1RB2iaZhtvey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dataset"
      ],
      "metadata": {
        "id": "CWVYlSvlwVV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_augs = T.Compose([\n",
        "                        T.RandomRotation((-20, +20)),\n",
        "                        T.ToTensor() # (h, w, c) -> (c, h, w)\n",
        "              ])"
      ],
      "metadata": {
        "id": "HjmpFvnBwY2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.MNIST('MNIST/', download=True, train=True, transform=train_augs)"
      ],
      "metadata": {
        "id": "u1DDTsaxxGUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = trainset[25]\n",
        "plt.imshow(image.squeeze(), cmap='gray')"
      ],
      "metadata": {
        "id": "R4gVAwXNxYnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of images in trainset:\", len(trainset))"
      ],
      "metadata": {
        "id": "BJezrpd_xi7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dataset into batches"
      ],
      "metadata": {
        "id": "eFiJnx_Axusl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "0X8X4oocx2UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of batches in trainloader:\", len(trainloader))"
      ],
      "metadata": {
        "id": "7EiD_ZIcyTMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, _ = next(dataiter)\n",
        "print(image.shape)"
      ],
      "metadata": {
        "id": "7RGsd0ZzyYKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_tensor_images(tensor_img, num_images = 16, size=(1, 28, 28)):\n",
        "    unflat_img = tensor_img.detach().cpu()\n",
        "    img_grid = make_grid(unflat_img[:num_images], nrow=4)\n",
        "    plt.imshow(img_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rOdC0TxLygiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tensor_images(images, num_images=16)"
      ],
      "metadata": {
        "id": "x20i3_E_zA_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator Network"
      ],
      "metadata": {
        "id": "x_F0E5RIzC7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "Network : Discriminator\n",
        "\n",
        "input : (bs, 1, 28, 28)\n",
        "      |                                                                                               ---- SUMMARY ----\n",
        "      V\n",
        "Conv2d( in_channels = 1, out_channels = 16, kernel_size = (3,3), stride = 2)                           #(bs, 16, 13, 13)\n",
        "BatchNorm2d()                                                                                          #(bs, 16, 13, 13)\n",
        "LeakyReLU()                                                                                            #(bs, 16, 13, 13)\n",
        "      |\n",
        "      V\n",
        "Conv2d( in_channels = 16, out_channels = 32, kernel_size = (5,5), stride = 2)                          #(bs, 32, 5, 5)\n",
        "BatchNorm2d()                                                                                          #(bs, 32, 5, 5)\n",
        "LeakyReLU()                                                                                            #(bs, 32, 5, 5)\n",
        "      |\n",
        "      V\n",
        "Conv2d( in_channels = 32, out_channels = 64, kernel_size = (5,5), stride = 2)                          #(bs, 64, 1, 1)\n",
        "BatchNorm2d()                                                                                          #(bs, 64, 1, 1)\n",
        "LeakyReLU()                                                                                            #(bs, 64, 1, 1)\n",
        "      |\n",
        "      V\n",
        "Flatten()                                                                                              #(bs, 64)\n",
        "Linear(in_features = 64, out_features = 1)                                                             #(bs, 1)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "P1tfZgsaz6M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_disc_block(in_channels, out_channels, kernel_size, stride):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size, stride),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.LeakyReLU(0.2)\n",
        "  )"
      ],
      "metadata": {
        "id": "D83hZQJZz95k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.block1 = get_disc_block(1, 16, (3, 3), 2)\n",
        "    self.block2 = get_disc_block(16, 32, (5, 5), 2)\n",
        "    self.block3 = get_disc_block(32, 64, (5, 5), 2)\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear = nn.Linear(in_features=64, out_features=1)\n",
        "\n",
        "\n",
        "  def forward(self, images):\n",
        "    x1 = self.block1(images)\n",
        "    x2 = self.block2(x1)\n",
        "    x3 = self.block3(x2)\n",
        "\n",
        "    x4 = self.flatten(x3)\n",
        "    x5 = self.linear(x4)\n",
        "\n",
        "    return x5"
      ],
      "metadata": {
        "id": "hNktVtrf0jvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator()\n",
        "D.to(device)\n",
        "\n",
        "summary(D, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "id": "ARnoPbyb1prw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator Network"
      ],
      "metadata": {
        "id": "Qo7F1cSm118Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "Network : Generator\n",
        "\n",
        "z_dim = 64\n",
        "input : (bs,z_dim)\n",
        "\n",
        "      |\n",
        "      | Reshape\n",
        "      V\n",
        "\n",
        "input : (bs, channel, height, width) -> (bs, z_dim , 1 , 1)\n",
        "      |                                                                                               ---- SUMMARY ----\n",
        "      V\n",
        "ConvTranspose2d( in_channels = z_dim, out_channels = 256, kernel_size = (3,3), stride = 2)             #(bs, 256, 3, 3)\n",
        "BatchNorm2d()                                                                                          #(bs, 256, 3, 3)\n",
        "ReLU()                                                                                                 #(bs, 256, 3, 3)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 256, out_channels = 128, kernel_size = (4,4), stride = 1)               #(bs, 128, 6, 6)\n",
        "BatchNorm2d()                                                                                          #(bs, 128, 6, 6)\n",
        "ReLU()                                                                                                 #(bs, 128, 6, 6)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 128, out_channels = 64, kernel_size = (3,3), stride = 2)                #(bs, 64, 13, 13)\n",
        "BatchNorm2d()                                                                                          #(bs, 64, 13, 13)\n",
        "ReLU()                                                                                                 #(bs, 64, 13, 13)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 64, out_channels = 1, kernel_size = (4,4), stride = 2)                  #(bs, 1, 28, 28)\n",
        "Tanh()                                                                                                 #(bs, 1, 28, 28)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "DW_T2uln15PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gen_block(in_channels, out_channels, kernel_size, stride, final_block=False):\n",
        "  if final_block:\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  return nn.Sequential(\n",
        "      nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU()\n",
        "  )"
      ],
      "metadata": {
        "id": "RSkHoPd22FFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_dim):\n",
        "    super(Generator, self).__init__()\n",
        "    self.noise_dim = noise_dim\n",
        "\n",
        "    self.block1 = get_gen_block(noise_dim, 256, (3, 3), 2)\n",
        "    self.block2 = get_gen_block(256, 128, (4, 4), 1)\n",
        "    self.block3 = get_gen_block(128, 64, (3, 3), 2)\n",
        "    self.block4 = get_gen_block(64, 1, (4, 4), 2, final_block=True)\n",
        "\n",
        "\n",
        "  def forward(self, r_noise_vec):\n",
        "    # (bs, noise_dim) -> (bs, noise_dim, 1, 1)\n",
        "\n",
        "    x = r_noise_vec.view(-1, self.noise_dim, 1, 1)\n",
        "\n",
        "    x1 = self.block1(x)\n",
        "    x2 = self.block2(x1)\n",
        "    x3 = self.block3(x2)\n",
        "    x4 = self.block4(x3)\n",
        "\n",
        "    return x4"
      ],
      "metadata": {
        "id": "B0w2PS2v22n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator(noise_dim)\n",
        "G.to(device)\n",
        "\n",
        "summary(G, input_size=(1, noise_dim))"
      ],
      "metadata": {
        "id": "AqKH3_ol4BIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace Random initialized weights to Normal weights\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "B5S-1fVI4NqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = D.apply(weights_init)\n",
        "G = G.apply(weights_init)"
      ],
      "metadata": {
        "id": "EkvtLQa14Rvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss function and Load optimizer"
      ],
      "metadata": {
        "id": "zwL37Xph4eLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def real_loss(disc_pred):\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  loss = criterion(disc_pred, torch.ones_like(disc_pred))\n",
        "  return loss\n",
        "\n",
        "\n",
        "def fake_loss(disc_pred):\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  loss = criterion(disc_pred, torch.zeros_like(disc_pred))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "14fx8lxA4ivd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_opt = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta_1, beta_2))"
      ],
      "metadata": {
        "id": "aABhqmMj46QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "VB4ARMY-5EXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "  total_d_loss = 0.0\n",
        "  total_g_loss = 0.0\n",
        "\n",
        "  for real_img, _ in tqdm(trainloader):\n",
        "    real_img = real_img.to(device)\n",
        "    noise = torch.randn(batch_size, noise_dim, device=device)\n",
        "\n",
        "    # Find loss and update weights for D\n",
        "    D_opt.zero_grad()\n",
        "    fake_img = G(noise)\n",
        "    D_pred = D(fake_img)\n",
        "    D_fake_loss = fake_loss(D_pred)\n",
        "\n",
        "    D_pred = D(real_img)\n",
        "    D_real_loss = real_loss(D_pred)\n",
        "\n",
        "    D_loss = (D_fake_loss + D_real_loss) / 2\n",
        "    total_d_loss += D_loss.item()\n",
        "\n",
        "    D_loss.backward()\n",
        "    D_opt.step()\n",
        "\n",
        "    # Find loss and update weights for G\n",
        "    G_opt.zero_grad()\n",
        "    noise = torch.randn(batch_size, noise_dim, device=device)\n",
        "\n",
        "    fake_img = G(noise)\n",
        "    D_pred = D(fake_img)\n",
        "    G_loss = real_loss(D_pred)\n",
        "    total_g_loss += G_loss.item()\n",
        "\n",
        "    G_loss.backward()\n",
        "    G_opt.step()\n",
        "\n",
        "\n",
        "  avg_d_loss = total_d_loss / len(trainloader)\n",
        "  avg_g_loss = total_g_loss / len(trainloader)\n",
        "\n",
        "  print(\"Epoch: {} | D_loss: {} | G_loss: {}\".format(i+1, avg_d_loss, avg_g_loss))\n",
        "\n",
        "  if i in [0, epochs-1]:\n",
        "    show_tensor_images(fake_img)"
      ],
      "metadata": {
        "id": "pfAXyWli5IwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and test loading generator and discriminator"
      ],
      "metadata": {
        "id": "2G0AlL5XDcm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(D.state_dict(), 'discriminator.pth')\n",
        "torch.save(G.state_dict(), 'generator.pth')"
      ],
      "metadata": {
        "id": "K2kpyZTO80bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Disc = Discriminator()\n",
        "Disc.load_state_dict(torch.load('discriminator.pth', weights_only=True))\n",
        "\n",
        "Gen = Generator(noise_dim)\n",
        "Gen.load_state_dict(torch.load('generator.pth', weights_only=True))"
      ],
      "metadata": {
        "id": "9KxITWsXBh-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Disc.eval()"
      ],
      "metadata": {
        "id": "Np9wMTxLCWVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gen.eval()"
      ],
      "metadata": {
        "id": "eoLkDRs7DJJB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}