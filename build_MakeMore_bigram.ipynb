{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGMBQ+4rOhekgj5/ymqBg2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanayPhatak/Google_Colab_Projects/blob/main/build_MakeMore_bigram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating mock of MakeMore by Andrej Karpathy.\n",
        "Video Link: https://www.youtube.com/watch?v=PaCmpygFfXo"
      ],
      "metadata": {
        "id": "1hfKDuDlKJ9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import requests\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "r8DM0YFaNyKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
        "read_data = requests.get(url).content\n",
        "raw_words = read_data.splitlines()\n",
        "words = [w.decode('ascii') for w in raw_words]"
      ],
      "metadata": {
        "id": "pTG1I8hYKUf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:10]"
      ],
      "metadata": {
        "id": "TbQEGcN4N9f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Bigram language model for MakeMore\n",
        "\n",
        "Bigram is a pair of alphabets. It takes a character and predicts the following character."
      ],
      "metadata": {
        "id": "5mSHYCoiOQ1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = {}\n",
        "for w in words:\n",
        "  chs = ['<S>'] + list(w) + ['<E>']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    bigram = (ch1, ch2)\n",
        "    b[bigram] = b.get(bigram, 0) + 1"
      ],
      "metadata": {
        "id": "OtUwiXvkP1rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(b.items(), key = lambda kv: -kv[1])"
      ],
      "metadata": {
        "id": "ahGnqNBPQOCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((27, 27), dtype = torch.int32)"
      ],
      "metadata": {
        "id": "SpwCz7b0RgTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0"
      ],
      "metadata": {
        "id": "sZDa6GFxSUqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    N[ix1, ix2] += 1"
      ],
      "metadata": {
        "id": "sxDj_C-fSC_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = {i:s for s, i in stoi.items()}"
      ],
      "metadata": {
        "id": "I3smCZflTBMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N, cmap='Blues')\n",
        "for i in range(27):\n",
        "  for j in range(27):\n",
        "    chstr = itos[i] + itos[j]\n",
        "    plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
        "    plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color=\"gray\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "2tUWtcLITjIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "p = torch.rand(3, generator=g)\n",
        "p = p / p.sum()\n",
        "p"
      ],
      "metadata": {
        "id": "rdjoG2HpT6e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multinomial(p, num_samples=200, replacement=True, generator=g)"
      ],
      "metadata": {
        "id": "U5A-Ec4DXwZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PyTorch sum function\n",
        "\n",
        "torch.sum() has keepdim param. that retains a dimension after the operation\n",
        "\n",
        "* torch.sum(1, keepdim=true) sums up along the row\n",
        "\n",
        "* torch.sum(0, keepdim=true) sums up along the column\n",
        "\n",
        "**Also see broadcasting rules of PyTorch: https://pytorch.org/docs/stable/notes/broadcasting.html**"
      ],
      "metadata": {
        "id": "nZuzMZ8NfoDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P = (N+1).float()\n",
        "P /= P.sum(1, keepdim=True)\n",
        "\n",
        "#                      P -> 27, 27\n",
        "# P.sum(1, keepdim=True) -> 27,  1\n",
        "\n",
        "# They are broadcastable according to broadcasting rule of pytorch\n",
        "# Resulting tensor will have shape 27, 27"
      ],
      "metadata": {
        "id": "DXbE9CptbBjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P[0].sum()"
      ],
      "metadata": {
        "id": "p8JpoY7TjlW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(20):\n",
        "  ix = 0\n",
        "  out = []\n",
        "  while True:\n",
        "    p = P[ix]\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "id": "rigBk5mjYAid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Negative Log Likehood** is a very useful loss function in this case\n",
        "It is negative of log of products of probabilites of model parameters in use.\n",
        "\n",
        "*It is common to take average negative log likehood to give an overall picture of the loss of the model*\n",
        "\n",
        "--- Minimizing the negative log likehood is the goal (lower it is, better is the model)\n",
        "\n",
        "Here, -log(P[ix1, ix2])\n",
        "\n",
        "If in some case, model is 0% likely to predict a output, loss will be infinity due to log function.\n",
        "* Therefore, we add an initial value to every data element to avoid such a situation (this is called model smoothing)."
      ],
      "metadata": {
        "id": "lORGIyCRZ0i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_likehood = 0.0\n",
        "n = 0\n",
        "\n",
        "for w in words[:3]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1, ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likehood += logprob\n",
        "    n += 1\n",
        "    print(f'{ch1}{ch2}: {prob=: 4f}, {logprob=: 4f}')\n",
        "\n",
        "print(f'{log_likehood=}')\n",
        "nll = -log_likehood\n",
        "print(f'{nll=}')\n",
        "print(f'{(nll/n)=}')"
      ],
      "metadata": {
        "id": "nLEPxiaxrH0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "HZ2OnKKisPH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a neural for the same above..."
      ],
      "metadata": {
        "id": "4LXVKEB9wk54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words[0], words[:1]"
      ],
      "metadata": {
        "id": "F3F3I39jzdOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training set of bigrams (x, y)\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:1]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "\n",
        "print(f'{xs=}, {ys=}')"
      ],
      "metadata": {
        "id": "oFxqOPy4wxld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot encoding the tensors xs and ys\n",
        "xenc = torch.nn.functional.one_hot(xs, num_classes=27).float()\n",
        "xenc, xenc.shape"
      ],
      "metadata": {
        "id": "UKzzRAqQygAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(xenc), xenc.dtype"
      ],
      "metadata": {
        "id": "w3KEYyu8ysUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((27, 27))\n",
        "xenc @ W\n",
        "\n",
        "# '@' is a matrix multiplication operator in PyTorch"
      ],
      "metadata": {
        "id": "8aEelc-By4Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = (xenc @ W) # log-counts\n",
        "counts = logits.exp() # Equivalent N\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "probs"
      ],
      "metadata": {
        "id": "zx4GB-m30e5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Summary so far :-"
      ],
      "metadata": {
        "id": "ry_TEeLermDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs"
      ],
      "metadata": {
        "id": "Q0lCPzDbs4vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ys"
      ],
      "metadata": {
        "id": "g3W6YJaEs6yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly initialize 27 neurons' weights, each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "w = torch.randn((27, 27), generator=g)"
      ],
      "metadata": {
        "id": "Q-N5lQ9as7Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = torch.nn.functional.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# btw: the last 2 lines here are together called 'softmax'\n",
        "# Therefore: Softmax = ((xenc @ W).exp()) / ((xenc @ W).exp()).sum(1, keepdims=True)\n",
        "# Softmax is an activation function for neurons in the neural network (generally used on output layer)."
      ],
      "metadata": {
        "id": "MvL6tbIdtQM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs.shape"
      ],
      "metadata": {
        "id": "3qtKmsaruPqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Raw input: ', words[:1])\n",
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "  # i-th bigram\n",
        "  x = xs[i].item() # input character index\n",
        "  y = ys[i].item() # label character index\n",
        "  print('--------------')\n",
        "  print(f'Bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x}, {y})')\n",
        "  print('Input to the neural network: ', x)\n",
        "  print('Output of the neural network: ', probs[i])\n",
        "  print('Label (actual next character): ', y)\n",
        "  p = probs[i, y]\n",
        "  print('Prbability assignaed by the network to the correct character: ', p.item())\n",
        "  logp = torch.log(p)\n",
        "  print('Log likehood: ', logp.item())\n",
        "  nll = -logp\n",
        "  print('Negative log likehood: ', nll.item())\n",
        "  nlls[i] = nll\n",
        "\n",
        "print('===============')\n",
        "print('Average negative log likehood, i.e. loss = ', nlls.mean().item())"
      ],
      "metadata": {
        "id": "SoeCvOuquUYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *--------- !!! OPTIMIZATION !!! ---------*"
      ],
      "metadata": {
        "id": "X_Sk8d6vv2nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys"
      ],
      "metadata": {
        "id": "MpOz0zIq0dkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "2PUE0ylF1ak4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "xenc = torch.nn.functional.one_hot(xs, num_classes=27).float()\n",
        "logits = xenc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "loss = -probs[torch.arange(5), ys].log().mean()"
      ],
      "metadata": {
        "id": "G_XdZdBa1eDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.item())"
      ],
      "metadata": {
        "id": "LCl-BCLP3049"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Pass\n",
        "W.grad = None # set to zero the gradient (none is better than 0)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "m1FSCwFD1r9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.data += -0.1 * W.grad"
      ],
      "metadata": {
        "id": "q_zgeRkG3Tji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "## Compiling everything done till now to work in a flow"
      ],
      "metadata": {
        "id": "iUPFfEFa4TaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('Number of examples: ', num)"
      ],
      "metadata": {
        "id": "jEDLUON94bmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the network\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "Zw2SPuED5Euy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent\n",
        "for k in range(10):\n",
        "\n",
        "  # Forward pass\n",
        "  xenc = torch.nn.functional.one_hot(xs, num_classes=27).float()\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean()\n",
        "  print(loss.item())\n",
        "\n",
        "  # Gradient-based optimization:\n",
        "  # Backward pass\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # Update weights\n",
        "  W.data += -100 * W.grad"
      ],
      "metadata": {
        "id": "2t5N56ut5V-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, sample from the 'neural network' model\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    # --------------\n",
        "    # BEFORE:\n",
        "    # p = P[ix]\n",
        "    # --------------\n",
        "    # NOW:\n",
        "    xenc = torch.nn.functional.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    p = counts / counts.sum(1, keepdims=True)\n",
        "    # --------------\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "\n",
        "  print(''.join(out))\n"
      ],
      "metadata": {
        "id": "NE91R3X56JNo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}